# -*- coding: utf-8 -*-
"""GPU_Run.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1G4vwG9MbA3Lfv7i2xsqpr1HrwWumALpm

# Preparing to start

## Preparing the enviroment


*   Attaching the libraries
*   Setting the global variables
*   Defining new paths
"""

import sys
import warnings
from google.colab import drive

DATASET         = 'CICIDS2017_sample.csv'
TARGET          = 'Label'
CLUSTER_COUNTS  = 7
BASE_PATH       = '/content/gdrive/MyDrive/Nasim/'
DATA_PATH       = BASE_PATH + ''
MODULE_PATH     = BASE_PATH + '/CICIDS_DATASETS/Modules'

warnings.filterwarnings("ignore")
sys.path.append(MODULE_PATH)
drive.mount('/content/gdrive')

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,precision_recall_fscore_support
from sklearn.metrics import f1_score,roc_auc_score
from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.cluster import KMeans
from sklearn.tree import DecisionTreeClassifier
from sklearn.cluster import MiniBatchKMeans
from sklearn.metrics.pairwise import euclidean_distances
import xgboost as xgb
from xgboost import plot_importance
from sklearn.feature_selection import mutual_info_classif
from FCBF_module import FCBF, FCBFK, FCBFiP, get_i
from sklearn.decomposition import KernelPCA, PCA
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from imblearn.over_sampling import SMOTE
from sklearn.preprocessing import MinMaxScaler
from sklearn.tree import DecisionTreeClassifier

from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

"""## Modules

*   Defined all procedures for analysing the dada

### Components
"""

def load_dataset(file_name, target_name = TARGET, path = DATA_PATH):
  print(">>> Loading dataset:")
  if file_name.endswith('csv'):
    data = pd.read_csv(path + file_name)
    classes = np.empty((0,))
    n_labels = 'Not Exists'
    n_classes = 'Unrecognized'
    if target_name is not None:
      classes = pd.unique(data[target_name])
      n_labels = data[target_name].shape[0]
      n_classes = classes.shape[0]
    print(f"\tFeatures: {data.shape[0]}\n\tLabels: {n_labels}\n\tClasses: ({n_classes}) {classes}")
    return data

def feature_label_seperator(data, target_name = TARGET):
  print(">>> Seperating Feature & Labels:")
  X = data.iloc[:, data.columns != target_name]
  y = data[target_name]
  print(f"\tOriginal: {data.shape}\n\tFeatures: {X.shape[0]}\n\tLabels: {y.shape[0]}")
  return X, y

def feature_lable_combinator(features, labels, target_name = TARGET):
  print(">>> Features and labels are combined:")
  features = pd.DataFrame(features)
  data = features.copy()
  data[target_name] = labels
  print(f"\tOriginal: {features.shape}\n\tResult: {data.shape}")
  return data

def drop_sample(features, labels, target_values):
  print(f">>> Drop minor sample: {target_values}: {features.shape[0]}")
  data = feature_lable_combinator(features, labels)
  if len(target_values) > 0:
    data = data.drop(data[data[TARGET].isin(target_values)].index)
  features, labels = feature_label_seperator(data)
  print(f"\tOriginal: {features.shape[0]}\n\tResult: {features.shape[0]}")
  return features, labels

def min_max_normalizer(data):
  print(">>> Min-Max Normalizing:")
  scaler = MinMaxScaler(feature_range=(0, 1))
  result = scaler.fit(data)
  result = scaler.transform(data)
  print(f"\tDone --- {result.shape}\n\tMaximum: {result.max()}\n\tMinimum: {result.min()}")
  return result

def std_normalizer(data):
  numeric_features = data.dtypes[data.dtypes != 'object'].index
  data[numeric_features].apply(lambda x: (x - x.mean()) / (x.std()))
  data[numeric_features] = (data[numeric_features] - data[numeric_features].mean())/data[numeric_features].std()
  return data
  
def replace_misvalues(value, data):
  print(">>> Missed values replacment:")
  data.replace([np.inf, -np.inf], np.nan, inplace=True)
  nulls = data.isnull().sum().sum()
  print(f"\tDone --- {nulls} nulls is replaced by {value}")
  return data.fillna(value)

def label_encoder(labels):
  print(">>> Encoding labels:")
  labelencoder = LabelEncoder()
  en_labels = labelencoder.fit_transform(labels)
  print(f"\t{en_labels.shape[0]} labels are encoded as below:\n\tBefore: {pd.unique(labels.values.reshape(1, -1)[0])}\n\tAfter:  {pd.unique(en_labels)}")
  return en_labels

def minor_major_samples(max_frequency, data, target = TARGET):
  frequents = data[target].value_counts(normalize=True)
  targets   = frequents[frequents < max_frequency].index
  minors    = data[data[target].isin(targets)]
  majors    = data.drop(minors.index)
  print(f">>> Majority analisys:\n\tMajors: {majors.shape}\n\tMinors: {minors.shape}")
  return minors, majors

def typical_sampling(majors, minors, target = TARGET, n_clusters = 1000, fraction = 0.008):
  print(">>> Data Sampling:")
  X = majors.drop([target], axis=1)
  s = majors.shape
  kmeans = MiniBatchKMeans(n_clusters).fit(X)
  majors['klabel'] = kmeans.labels_
  majors = majors.groupby('klabel', group_keys=False).apply(lambda group: group.sample(frac=fraction))
  majors = majors.drop(['klabel'],axis=1)
  result = majors.append(minors)
  print(f"\tInput sahpe: {s}\n\tSampled Data:\n\t\tMajors: {majors.shape}\n\t\tMinors: {minors.shape}\n\tResult: {result.shape}\n\tNumber of clusters: {n_clusters}\n\tFraction: {fraction}", )
  return result

def select_important_features(features, labels, threshold = 0.9):
  print(">>> Mutual important features:")
  features = pd.DataFrame(features)
  labels   = pd.DataFrame(labels)
  importances = mutual_info_classif(features, labels)
  sum = np.sum(importances)
  important_features = sorted(zip(map(lambda x: round(x, 4), importances/sum), features), reverse=True)
  selected_features = []
  portion = 0
  for i in range(len(important_features)):
    portion = portion + important_features[i][0]
    selected_features.append(important_features[i][1])
    if portion >= threshold:
      break
  rdc_features = features[selected_features]
  print(f"\tOriginal: {features.shape}\n\tReduced:  {rdc_features.shape}")
  return rdc_features

def Fast_CB_FS(features, labels, n_features = 10):
  print(">>> Fast Correlation-Based Feature Selection:")
  features = np.array(features)
  labels   = np.array(labels)
  fcbfk = FCBFK(k = n_features)
  print(f"\tObj: {fcbfk} ---Started: {features.shape}")
  rdc_features = fcbfk.fit_transform(features, labels)
  print(f"\tOriginal: {features.shape}\n\tReduced:  {rdc_features.shape}")
  return rdc_features

def kpca(features, labels, n = 5):
  print(">>> Kernel PCA:")
  kpca = KernelPCA(n_components = n, kernel = 'rbf')
  kpca.fit(features, labels)
  rdc_features = kpca.transform(features)
  print(f"\t#N components: {n}\n\tOriginal: {features.shape}\n\tReduced: {rdc_features.shape}")
  return rdc_features

def LDA(data, labels, n = 6):
  print(">>> Linear Discriminant Analysis:")
  clf = LinearDiscriminantAnalysis()
  clf.fit(data, labels)
  features = clf.transform(data)
  print(f"\t# of components: {n}\n\t# of Seen Features: {clf.n_features_in_}\n\tOriginal: {data.shape}\n\tReduced:  {features.shape}\n\tClasses:  {clf.classes_}\n\tVariation: {clf.explained_variance_ratio_} = {np.sum(clf.explained_variance_ratio_)}")
  return features

def oversampling(features, labels, strategy = 'not majority'):
  print(">>> Oversampling:")
  oversample = SMOTE(sampling_strategy = strategy)
  x, y = oversample.fit_resample(features, labels)
  print(f"Total Samples: {x.shape[0]}\n{pd.DataFrame(y).value_counts()}")
  return x, y

def save_todrive(result, name):
  print(">>> Save results to drive:")
  result.to_csv(DATA_PATH + name, index=0)
  print(f"\tDone --- {DATA_PATH+name}")

"""### Combined modules"""

def preprocessing(data):
  print(f"\n----- PREPOCESSING OF : {data.shape} -----")
  ##### Fill empty values by 0 #####
  data = replace_misvalues(value = 0, data = data)

  ##### Feature and labels seperation #####
  features, labels = feature_label_seperator(data, TARGET)

  ##### Z-score normalization #####
  features = min_max_normalizer(features)

  ##### Encode all labels #####
  labels = label_encoder(labels)

  ##### retain the minority class instances and sample the majority class instances #####
  # data_minor, data_major = minor_major_samples(MINOR_RATE, data)

  ##### Data sampling #####
  # data =  typical_sampling(data_major, data_minor, TARGET, 1000, 0.008)

  ##### Same to drive #####
  # save_todrive(data, 'train_sampled_result.csv')

  ##### Feature reduction - mutual-information #####
  # features = select_important_features(features, labels, 0.9)

  ##### Fast corrolation-Based feature selection #####
  features = Fast_CB_FS(features, labels, n_features = 20)

  ##### Kernel PCA #####
  features = kpca(features, labels, 10)

  print(f"\n----- PREPOCESSING is COMPLETED : Samples: {features.shape[0]} Features: {features.shape[1]} Labels: {labels.shape} -----")
  return features, labels

"""### Confusion Matrix Visualization"""

def visualize(model, X_test, y_test, y_predict):
  if model is not None:
    scores = model.score(X_test, y_test)
    print('Accuracy:\t'+ str(scores))
  precision, recall, fscore, none = precision_recall_fscore_support(y_test, y_predict, average='weighted') 
  print('Precision:\t'+(str(precision)))
  print('Recall: \t'+(str(recall)))
  print('F1-score:\t'+(str(fscore))+'\n')
  print(classification_report(y_test, y_predict))
  cm=confusion_matrix(y_test, y_predict)
  f,ax=plt.subplots(figsize=(5,5))
  sns.heatmap(cm,annot=True,linewidth=0.5,linecolor="green",fmt=".0f",ax=ax)
  plt.xlabel("y_pred")
  plt.ylabel("y_true")
  plt.show()
  return scores if model is not None else None

"""### Supervised Learning"""

def S_Experiment(model, X_train, y_train, X_test, y_test):
  print(f'>>>>>----- Model: {str(model)} -----<<<<<\n')
  model.fit(X_train,y_train) 
  y_predict = model.predict(X_test)
  scores = visualize(model, X_test, y_test, y_predict)
  return model, y_predict, scores

"""### Unsupervised Learning"""

def U_Experiment(model, X_train, y_train, X_test, y_test):
  print(f'>>>>>----- Model: {str(model)} -----<<<<<\n')
  model.fit(X_train)
  y_clusters_train = model.predict(X_train)
  y_clusters_test  = model.predict(X_test)
  df_new = feature_lable_combinator(X_train, y_train)
  lbls  = np.unique(y_train)
  print('y_train       :', lbls)
  candidates = []
  for i in range(len(lbls)):
    class_samples = df_new[df_new[TARGET] == lbls[i]]
    candid  = np.Inf
    samples = []
    for j in range(len(model.cluster_centers_)):
      distance = euclidean_distances(model.cluster_centers_[j].reshape(1, -1), class_samples.iloc[:,:-1])
      if np.min(distance) < candid:
        candid = np.min(distance)
        samples.append((np.min(distance), np.argmin(distance), j))
    candidates.append(class_samples.iloc[min(samples, key = lambda t: t[0])[1]])
  samples = pd.DataFrame(candidates)
  sample_clusters = model.predict(samples.iloc[:, :-1])
  print('Sample predict:', sample_clusters)
  real_labels = np.array(samples.iloc[:,-1], dtype=int)
  print('Sample real   :', real_labels)
  # mapped_clusters = {int(real_labels[i]):sample_clusters[i] for i in range(len(real_labels))}
  # sample_clusters = model.predict(X_test)
  # y_predict = np.array([mapped_clusters[y_clusters_test[i]] for i in range(len(y_clusters_test))])
  # scores = visualize(None, X_test, y_test, y_predict)
  return model, y_clusters_test, y_clusters_train

"""# Preparing data for processing


*   Loading the dataset
*   Splitting teh dataset
*   Preprocessing the trainset

### Load and normalizing
"""

##### Loadinf the dataset #####
df = load_dataset(file_name = DATASET, path = DATA_PATH)

##### Fill empty values by 0 #####
data = replace_misvalues(value = 0, data = df)

##### Feature and labels seperation #####
features, labels = feature_label_seperator(data, TARGET)

##### Z-score normalization #####
# features = min_max_normalizer(features)

##### Encode all labels #####
labels = label_encoder(labels)

pd.DataFrame(labels).value_counts().sort_index()

# Oversampling
features, labels = oversampling(features, labels)

"""### Feature Reduction"""

##### retain the minority class instances and sample the majority class instances #####
# data_minor, data_major = minor_major_samples(MINOR_RATE, data)

##### Data sampling #####
# data =  typical_sampling(data_major, data_minor, TARGET, 1000, 0.008)

##### Same to drive #####
# save_todrive(data, 'train_sampled_result.csv')

##### Feature reduction - mutual-information #####
# features_m = select_important_features(features, labels, 0.9)
##### Fast corrolation-Based feature selection #####
# features_r = Fast_CB_FS(features_m, labels, n_features = 20)
##### Same to drive #####
# save_todrive(pd.DataFrame(features_r), 'fcbf_reduced_features_ADASYN.csv')

##### Kernel PCA #####
# features = kpca(features, labels, 5)

##### Same to drive #####
# save_todrive(pd.DataFrame(features_r), 'fcbf_reduced_features.csv')

##### Loadinf the dataset #####
features = load_dataset(file_name = 'fcbf_reduced_features.csv', target_name = None, path = DATA_PATH)

##### Loadinf the dataset #####
# features = load_dataset(file_name = 'fcbf_reduced_features_ADASYN.csv', target_name = None, path = DATA_PATH)

#Using Pearson Correlation
plt.figure(figsize=(7,7))
cor = pd.DataFrame(features).corr()
sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)
plt.show()

##### Linear Discriminant Analysis #####
features = LDA(features, labels)

#Using Pearson Correlation
plt.figure(figsize=(7,7))
cor = pd.DataFrame(features).corr()
sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)
plt.show()

from pandas.plotting import scatter_matrix
vis = scatter_matrix(pd.DataFrame(features), alpha=0.2, figsize=(10, 10), diagonal='kde')

# box-whisker plot to compare regression models
import matplotlib.pyplot as plt 
figure = plt.figure(figsize = (10,10))

trans_features = pd.DataFrame(features).T

figure.suptitle('Regression models comparison')
axis = figure.add_subplot(111)
plt.boxplot(trans_features)
axis.set_xticklabels(trans_features, rotation = 45, ha="right")
axis.set_ylabel("Mean Absolute Error (MAE)")
plt.margins(0.05, 0.1)

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = 0.2, random_state = 0, stratify = labels)
print(f">>> Dataset is splitted to:\n\tTrain Set: {X_train.shape}\t| Test Set: {X_test.shape} | All type of: {type(X_test)}")

"""
### Training the model"""

from sklearn.mixture import GaussianMixture
from operator import itemgetter
gm = GaussianMixture(n_components = CLUSTER_COUNTS, verbose = 2, verbose_interval = 5, random_state=0).fit(X_train)
gm_pred_clusters = gm.predict(X_train)
df_k = feature_lable_combinator(X_train, y_train)
df_k = feature_lable_combinator(df_k, gm_pred_clusters, 'G_Cluster')

fig, ax = plt.subplots(CLUSTER_COUNTS, 1)
plt.subplots_adjust(top=3)
priors = []
for i in range(CLUSTER_COUNTS):
  frq = df_k[df_k['G_Cluster'] == i][TARGET].value_counts(normalize=True).sort_index()
  priors.append([(frq.index[i], frq.values[i]) for i in range(len(frq))])
  ax[i].bar(frq.index, frq.values)
print(f'The probablity of each label existance in different clusters from 0 to 6')

"""### Finalizing"""

y_gm = gm.predict(X_test)
y_gm = np.array([max(priors[y_gm[i]], key=itemgetter(1))[0] for i in range(len(y_gm))], dtype=int)
# df_k = feature_lable_combinator(df_k, gm_pred_labels, 'G_Label')

import time
cluster = 'G_Cluster'
models = [RandomForestClassifier(n_estimators = 50) for i in range(CLUSTER_COUNTS)]
subsets = []
s_t_time = time.time()
for i in range(CLUSTER_COUNTS):
  subset = df_k[df_k[cluster] == i]
  f = subset.iloc[:, subset.columns.isin(range(CLUSTER_COUNTS))]
  l = subset[TARGET]
  subsets.append(np.unique(l))
  start_time = time.time()
  models[i].fit(f, l)
  # models[i][1].fit(f, l)
  end_tiem = time.time() - start_time
  print(f'Classifier {i+1} is trained in [{np.round(end_tiem, 3)} sec] with [{len(l)}] of samples, Bised with: [{np.bincount(l).argmax()}] in Cluster [{i}] of {np.unique(l)} ')
  print(l.value_counts())
print('--------------------------')
print(f'>>>>> Total training time: [{np.round(time.time() - s_t_time, 3)} sec]')

intersects = [[j for j in range(len(subsets)) if np.isin(subsets[i], subsets[j]).all()] for i in range(CLUSTER_COUNTS)]

intersects

from tqdm import tqdm
clusters = gm.predict(X_test)
y_pred = np.array([models[clusters[i]].predict(X_test[i].reshape(1, -1)) for i in tqdm(range(len(clusters)))], dtype = int).flatten()

clusters = gm.predict(X_test)
y_pred = np.empty((0,), dtype = int)
inv = 500
for i in range(len(clusters)):
  preds = np.empty((0,), dtype = int)
  for j in range(len(intersects[clusters[i]])):
    preds = np.append(preds, models[j].predict(X_test[i].reshape(1, -1)))
  if i % inv == 0: print(f"Cluster: {i} - Subset: {intersects[clusters[i]]}\n\tPredictions: {preds} >>>> ({np.bincount(preds).argmax()})")
  y_pred = np.append(y_pred, np.bincount(preds).argmax())

from sklearn.metrics import accuracy_score
print(f'Total Accuracy: {np.round(accuracy_score(y_test, y_pred), 5)*100}%')

visualize(None, X_test, y_test, y_pred)

pd.DataFrame(labels).value_counts()